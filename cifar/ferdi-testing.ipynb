{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84febe3e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from helpers import get_cpu, get_gpu, get_dataloader, train, test, make_Net\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eec3941f-a8a8-4a9c-84af-66b39b33e970",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu = get_gpu()\n",
    "trainloader = get_dataloader(256)\n",
    "testloader = get_dataloader(256, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5337ba9a-286a-4981-af73-286c24348fd7",
   "metadata": {},
   "source": [
    "# Test 1 - Different Conv layer count (1 to 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e22aa384-dfc4-4c73-9f71-7d464712adef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now training for 0 conv. layers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ferdi\\Development\\traffic-signal-control\\cifar\\helpers.py:244: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(self.last_layer(x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc:  58\n",
      "Now training for 1 conv. layers...\n",
      "Acc:  62\n",
      "Now training for 2 conv. layers...\n",
      "Acc:  60\n",
      "Now training for 3 conv. layers...\n",
      "Acc:  59\n",
      "Now training for 4 conv. layers...\n",
      "Acc:  60\n",
      "Now training for 5 conv. layers...\n",
      "Acc:  60\n"
     ]
    }
   ],
   "source": [
    "# Test 1 - Different neural network depths\n",
    "# c1 = [32, 5]\n",
    "c1 = {\"kernel_size\": 5, \"out_channels\": 32, \"padding\": 3}\n",
    "# c2 = [64, 3]\n",
    "c2 = {\"kernel_size\": 3, \"out_channels\": 64, \"padding\": 2}\n",
    "\n",
    "nets1 = []\n",
    "accs1 = []\n",
    "for i in range(6):\n",
    "    print(f\"Now training for {i} conv. layers...\")\n",
    "    cnn = [c1]\n",
    "    for _ in range(i):\n",
    "        cnn.append(c2)\n",
    "    Net = make_Net(cnn, [1200, 84*5], pool=nn.MaxPool2d(2, 2))\n",
    "    nets1.append(train(Net, trainloader, optim.SGD, device=gpu, lr=0.007, momentum=0.9))\n",
    "    accs1.append(test(nets1[-1], testloader, device=gpu))\n",
    "    print(f\"Acc: {accs1[-1]: .0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4beec775-3e76-4643-8a59-cedb30c64e58",
   "metadata": {},
   "source": [
    "# Test 2 - Different Lin layer count (1 to 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96c01c64-eb28-47da-a107-64af5489290b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now training for 0 lin. layers\n",
      "Acc:  58\n",
      "Now training for 1 lin. layers\n",
      "Acc:  60\n",
      "Now training for 2 lin. layers\n",
      "Acc:  63\n",
      "Now training for 3 lin. layers\n",
      "Acc:  63\n",
      "Now training for 4 lin. layers\n",
      "Acc:  63\n",
      "Now training for 5 lin. layers\n",
      "Acc:  62\n"
     ]
    }
   ],
   "source": [
    "conv = [{\"kernel_size\": 5, \"out_channels\": 32, \"padding\": 3},\n",
    "        {\"kernel_size\": 3, \"out_channels\": 64, \"padding\": 2}]\n",
    "\n",
    "nets2 = []\n",
    "accs2 = []\n",
    "for i in range(6):\n",
    "    print(f\"Now training for {i+1} lin. layers\")\n",
    "    lins = []\n",
    "    for _ in range(i):\n",
    "        lins.append(1200)\n",
    "    Net = make_Net(conv, lins, pool=nn.MaxPool2d(2, 2))\n",
    "    nets2.append(train(Net, trainloader, optim.SGD, device=gpu, lr=0.007, momentum=0.9))\n",
    "    accs2.append(test(nets2[-1], testloader, device=gpu))\n",
    "    print(f\"Acc: {accs2[-1]: .0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d741ee-b976-4107-b12e-234eea19b6ef",
   "metadata": {},
   "source": [
    "# Test 3 - Different permutations of 2 hidden layer sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5510f891-68c3-42db-8340-c9a93fa25c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now training for linear layers of size: 10 & 10\n",
      "Acc:  38\n",
      "Now training for linear layers of size: 10 & 200\n",
      "Acc:  54\n",
      "Now training for linear layers of size: 10 & 400\n",
      "Acc:  57\n",
      "Now training for linear layers of size: 10 & 1200\n",
      "Acc:  57\n",
      "Now training for linear layers of size: 10 & 2400\n",
      "Acc:  54\n",
      "Now training for linear layers of size: 10 & 6000\n",
      "Acc:  58\n",
      "Now training for linear layers of size: 200 & 10\n",
      "Acc:  41\n",
      "Now training for linear layers of size: 200 & 200\n",
      "Acc:  61\n",
      "Now training for linear layers of size: 200 & 400\n",
      "Acc:  60\n",
      "Now training for linear layers of size: 200 & 1200\n",
      "Acc:  63\n",
      "Now training for linear layers of size: 200 & 2400\n",
      "Acc:  62\n",
      "Now training for linear layers of size: 200 & 6000\n",
      "Acc:  64\n",
      "Now training for linear layers of size: 400 & 10\n",
      "Acc:  38\n",
      "Now training for linear layers of size: 400 & 200\n",
      "Acc:  60\n",
      "Now training for linear layers of size: 400 & 400\n",
      "Acc:  60\n",
      "Now training for linear layers of size: 400 & 1200\n",
      "Acc:  62\n",
      "Now training for linear layers of size: 400 & 2400\n",
      "Acc:  62\n",
      "Now training for linear layers of size: 400 & 6000\n",
      "Acc:  61\n",
      "Now training for linear layers of size: 1200 & 10\n",
      "Acc:  41\n",
      "Now training for linear layers of size: 1200 & 200\n",
      "Acc:  61\n",
      "Now training for linear layers of size: 1200 & 400\n",
      "Acc:  62\n",
      "Now training for linear layers of size: 1200 & 1200\n",
      "Acc:  62\n",
      "Now training for linear layers of size: 1200 & 2400\n",
      "Acc:  63\n",
      "Now training for linear layers of size: 1200 & 6000\n",
      "Acc:  63\n",
      "Now training for linear layers of size: 2400 & 10\n",
      "Acc:  38\n",
      "Now training for linear layers of size: 2400 & 200\n",
      "Acc:  61\n",
      "Now training for linear layers of size: 2400 & 400\n",
      "Acc:  62\n",
      "Now training for linear layers of size: 2400 & 1200\n",
      "Acc:  62\n",
      "Now training for linear layers of size: 2400 & 2400\n",
      "Acc:  63\n",
      "Now training for linear layers of size: 2400 & 6000\n",
      "Acc:  64\n",
      "Now training for linear layers of size: 6000 & 10\n",
      "Acc:  35\n",
      "Now training for linear layers of size: 6000 & 200\n",
      "Acc:  64\n",
      "Now training for linear layers of size: 6000 & 400\n",
      "Acc:  63\n",
      "Now training for linear layers of size: 6000 & 1200\n",
      "Acc:  63\n",
      "Now training for linear layers of size: 6000 & 2400\n",
      "Acc:  62\n",
      "Now training for linear layers of size: 6000 & 6000\n",
      "Acc:  63\n"
     ]
    }
   ],
   "source": [
    "from itertools import permutations, product\n",
    "\n",
    "conv = [{\"kernel_size\": 5, \"out_channels\": 32, \"padding\": 3},\n",
    "        {\"kernel_size\": 3, \"out_channels\": 64, \"padding\": 2}]\n",
    "\n",
    "sizes = [10, 200, 400, 1200, 2400, 6000]\n",
    "\n",
    "nets3 = []\n",
    "accs3 = [] \n",
    "\n",
    "for lins in list(product(sizes, repeat=2)):\n",
    "    print(f\"Now training for linear layers of size: {lins[0]} & {lins[1]}\")\n",
    "    Net = make_Net(conv, lins, pool=nn.MaxPool2d(2, 2))\n",
    "    nets3.append(train(Net, trainloader, optim.SGD, device=gpu, lr=0.007, momentum=0.9))\n",
    "    accs3.append(test(nets3[-1], testloader, device=gpu))\n",
    "    print(f\"Acc: {accs3[-1]: .0f}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bebcb4-468c-4c5f-bbf4-6e8e45cdb936",
   "metadata": {},
   "source": [
    "# Test 4 - Dropping Softmax on Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b882b696-49e9-4536-a632-8fcc7059347a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now training for linear layers of size: 10 & 10\n",
      "Acc:  60\n",
      "Now training for linear layers of size: 10 & 200\n",
      "Acc:  63\n",
      "Now training for linear layers of size: 10 & 400\n",
      "Acc:  65\n",
      "Now training for linear layers of size: 10 & 1200\n",
      "Acc:  65\n",
      "Now training for linear layers of size: 10 & 2400\n",
      "Acc:  65\n",
      "Now training for linear layers of size: 10 & 6000\n",
      "Acc:  63\n",
      "Now training for linear layers of size: 200 & 10\n",
      "Acc:  65\n",
      "Now training for linear layers of size: 200 & 200\n",
      "Acc:  69\n",
      "Now training for linear layers of size: 200 & 400\n",
      "Acc:  68\n",
      "Now training for linear layers of size: 200 & 1200\n",
      "Acc:  70\n",
      "Now training for linear layers of size: 200 & 2400\n",
      "Acc:  69\n",
      "Now training for linear layers of size: 200 & 6000\n",
      "Acc:  70\n",
      "Now training for linear layers of size: 400 & 10\n",
      "Acc:  64\n",
      "Now training for linear layers of size: 400 & 200\n",
      "Acc:  69\n",
      "Now training for linear layers of size: 400 & 400\n",
      "Acc:  69\n",
      "Now training for linear layers of size: 400 & 1200\n",
      "Acc:  68\n",
      "Now training for linear layers of size: 400 & 2400\n",
      "Acc:  68\n",
      "Now training for linear layers of size: 400 & 6000\n",
      "Acc:  67\n",
      "Now training for linear layers of size: 1200 & 10\n",
      "Acc:  65\n",
      "Now training for linear layers of size: 1200 & 200\n",
      "Acc:  69\n",
      "Now training for linear layers of size: 1200 & 400\n",
      "Acc:  70\n",
      "Now training for linear layers of size: 1200 & 1200\n",
      "Acc:  71\n",
      "Now training for linear layers of size: 1200 & 2400\n",
      "Acc:  69\n",
      "Now training for linear layers of size: 1200 & 6000\n",
      "Acc:  69\n",
      "Now training for linear layers of size: 2400 & 10\n",
      "Acc:  66\n",
      "Now training for linear layers of size: 2400 & 200\n",
      "Acc:  69\n",
      "Now training for linear layers of size: 2400 & 400\n",
      "Acc:  69\n",
      "Now training for linear layers of size: 2400 & 1200\n",
      "Acc:  71\n",
      "Now training for linear layers of size: 2400 & 2400\n",
      "Acc:  71\n",
      "Now training for linear layers of size: 2400 & 6000\n",
      "Acc:  69\n",
      "Now training for linear layers of size: 6000 & 10\n",
      "Acc:  65\n",
      "Now training for linear layers of size: 6000 & 200\n",
      "Acc:  70\n",
      "Now training for linear layers of size: 6000 & 400\n",
      "Acc:  70\n",
      "Now training for linear layers of size: 6000 & 1200\n",
      "Acc:  69\n",
      "Now training for linear layers of size: 6000 & 2400\n",
      "Acc:  70\n",
      "Now training for linear layers of size: 6000 & 6000\n",
      "Acc:  69\n"
     ]
    }
   ],
   "source": [
    "from itertools import permutations, product\n",
    "\n",
    "conv = [{\"kernel_size\": 5, \"out_channels\": 32, \"padding\": 3},\n",
    "        {\"kernel_size\": 3, \"out_channels\": 64, \"padding\": 2}]\n",
    "\n",
    "sizes = [10, 200, 400, 1200, 2400, 6000]\n",
    "\n",
    "nets4 = []\n",
    "accs4 = [] \n",
    "\n",
    "for lins in list(product(sizes, repeat=2)):\n",
    "    print(f\"Now training for linear layers of size: {lins[0]} & {lins[1]}\")\n",
    "    Net = make_Net(conv, lins, pool=nn.MaxPool2d(2, 2), drop_softmax=True)\n",
    "    nets4.append(train(Net, trainloader, optim.SGD, device=gpu, lr=0.007, momentum=0.9))\n",
    "    accs4.append(test(nets4[-1], testloader, device=gpu))\n",
    "    print(f\"Acc: {accs4[-1]: .0f}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16458f4-266e-48ea-8c6c-18bd50ac0bef",
   "metadata": {},
   "source": [
    "# Note on Softmax\n",
    "This is trained using F.CrossEntropyLoss(), which applies softmax internally - probably explaining why dropping the model's softmax improves perfromance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d50493d-3df6-4ab6-a571-7f67437d479e",
   "metadata": {},
   "source": [
    "# Test 5 - Lin Layer Combos pt. 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac37f158-d691-432a-996e-05508f50e9fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now training for linear layers of size: (200, 200, 200)\n",
      "Acc:  69\n",
      "Now training for linear layers of size: (200, 200, 400)\n",
      "Acc:  68\n",
      "Now training for linear layers of size: (200, 200, 1200)\n",
      "Acc:  68\n",
      "Now training for linear layers of size: (200, 200, 2400)\n",
      "Acc:  70\n",
      "Now training for linear layers of size: (200, 400, 200)\n",
      "Acc:  68\n",
      "Now training for linear layers of size: (200, 400, 400)\n",
      "Acc:  68\n",
      "Now training for linear layers of size: (200, 400, 1200)\n",
      "Acc:  69\n",
      "Now training for linear layers of size: (200, 400, 2400)\n",
      "Acc:  68\n",
      "Now training for linear layers of size: (200, 1200, 200)\n",
      "Acc:  68\n",
      "Now training for linear layers of size: (200, 1200, 400)\n",
      "Acc:  69\n",
      "Now training for linear layers of size: (200, 1200, 1200)\n",
      "Acc:  69\n",
      "Now training for linear layers of size: (200, 1200, 2400)\n",
      "Acc:  69\n",
      "Now training for linear layers of size: (200, 2400, 200)\n",
      "Acc:  69\n",
      "Now training for linear layers of size: (200, 2400, 400)\n",
      "Acc:  68\n",
      "Now training for linear layers of size: (200, 2400, 1200)\n",
      "Acc:  70\n",
      "Now training for linear layers of size: (200, 2400, 2400)\n",
      "Acc:  69\n",
      "Now training for linear layers of size: (400, 200, 200)\n",
      "Acc:  69\n",
      "Now training for linear layers of size: (400, 200, 400)\n",
      "Acc:  68\n",
      "Now training for linear layers of size: (400, 200, 1200)\n",
      "Acc:  68\n",
      "Now training for linear layers of size: (400, 200, 2400)\n",
      "Acc:  68\n",
      "Now training for linear layers of size: (400, 400, 200)\n",
      "Acc:  67\n",
      "Now training for linear layers of size: (400, 400, 400)\n",
      "Acc:  69\n",
      "Now training for linear layers of size: (400, 400, 1200)\n",
      "Acc:  69\n",
      "Now training for linear layers of size: (400, 400, 2400)\n",
      "Acc:  69\n",
      "Now training for linear layers of size: (400, 1200, 200)\n",
      "Acc:  69\n",
      "Now training for linear layers of size: (400, 1200, 400)\n",
      "Acc:  69\n",
      "Now training for linear layers of size: (400, 1200, 1200)\n",
      "Acc:  67\n",
      "Now training for linear layers of size: (400, 1200, 2400)\n",
      "Acc:  69\n",
      "Now training for linear layers of size: (400, 2400, 200)\n",
      "Acc:  70\n",
      "Now training for linear layers of size: (400, 2400, 400)\n",
      "Acc:  68\n",
      "Now training for linear layers of size: (400, 2400, 1200)\n",
      "Acc:  69\n",
      "Now training for linear layers of size: (400, 2400, 2400)\n",
      "Acc:  69\n",
      "Now training for linear layers of size: (1200, 200, 200)\n",
      "Acc:  68\n",
      "Now training for linear layers of size: (1200, 200, 400)\n",
      "Acc:  69\n",
      "Now training for linear layers of size: (1200, 200, 1200)\n",
      "Acc:  68\n",
      "Now training for linear layers of size: (1200, 200, 2400)\n",
      "Acc:  69\n",
      "Now training for linear layers of size: (1200, 400, 200)\n",
      "Acc:  69\n",
      "Now training for linear layers of size: (1200, 400, 400)\n",
      "Acc:  69\n",
      "Now training for linear layers of size: (1200, 400, 1200)\n",
      "Acc:  70\n",
      "Now training for linear layers of size: (1200, 400, 2400)\n",
      "Acc:  69\n",
      "Now training for linear layers of size: (1200, 1200, 200)\n",
      "Acc:  70\n",
      "Now training for linear layers of size: (1200, 1200, 400)\n",
      "Acc:  70\n",
      "Now training for linear layers of size: (1200, 1200, 1200)\n",
      "Acc:  70\n",
      "Now training for linear layers of size: (1200, 1200, 2400)\n",
      "Acc:  69\n",
      "Now training for linear layers of size: (1200, 2400, 200)\n",
      "Acc:  70\n",
      "Now training for linear layers of size: (1200, 2400, 400)\n",
      "Acc:  70\n",
      "Now training for linear layers of size: (1200, 2400, 1200)\n",
      "Acc:  70\n",
      "Now training for linear layers of size: (1200, 2400, 2400)\n",
      "Acc:  69\n",
      "Now training for linear layers of size: (2400, 200, 200)\n",
      "Acc:  69\n",
      "Now training for linear layers of size: (2400, 200, 400)\n",
      "Acc:  70\n",
      "Now training for linear layers of size: (2400, 200, 1200)\n",
      "Acc:  70\n",
      "Now training for linear layers of size: (2400, 200, 2400)\n",
      "Acc:  70\n",
      "Now training for linear layers of size: (2400, 400, 200)\n",
      "Acc:  70\n",
      "Now training for linear layers of size: (2400, 400, 400)\n",
      "Acc:  71\n",
      "Now training for linear layers of size: (2400, 400, 1200)\n",
      "Acc:  70\n",
      "Now training for linear layers of size: (2400, 400, 2400)\n",
      "Acc:  70\n",
      "Now training for linear layers of size: (2400, 1200, 200)\n",
      "Acc:  70\n",
      "Now training for linear layers of size: (2400, 1200, 400)\n",
      "Acc:  69\n",
      "Now training for linear layers of size: (2400, 1200, 1200)\n",
      "Acc:  70\n",
      "Now training for linear layers of size: (2400, 1200, 2400)\n",
      "Acc:  70\n",
      "Now training for linear layers of size: (2400, 2400, 200)\n",
      "Acc:  69\n",
      "Now training for linear layers of size: (2400, 2400, 400)\n",
      "Acc:  70\n",
      "Now training for linear layers of size: (2400, 2400, 1200)\n",
      "Acc:  70\n",
      "Now training for linear layers of size: (2400, 2400, 2400)\n",
      "Acc:  68\n"
     ]
    }
   ],
   "source": [
    "from itertools import permutations, product\n",
    "\n",
    "conv = [{\"kernel_size\": 5, \"out_channels\": 32, \"padding\": 3},\n",
    "        {\"kernel_size\": 3, \"out_channels\": 64, \"padding\": 2}]\n",
    "\n",
    "sizes = [200, 400, 1200, 2400]\n",
    "\n",
    "nets5 = []\n",
    "accs5 = [] \n",
    "\n",
    "for lins in list(product(sizes, repeat=3)):\n",
    "    print(f\"Now training for linear layers of size: {lins}\")\n",
    "    Net = make_Net(conv, lins, pool=nn.MaxPool2d(2, 2), drop_softmax=True)\n",
    "    nets5.append(train(Net, trainloader, optim.SGD, device=gpu, lr=0.007, momentum=0.9))\n",
    "    accs5.append(test(nets5[-1], testloader, device=gpu))\n",
    "    print(f\"Acc: {accs5[-1]: .0f}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baba9ff5-c953-4338-970c-4fb7697aab02",
   "metadata": {},
   "source": [
    "# Trying ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b9f3cd2-4b48-4e10-b532-31c25e9164d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.digitalocean.com/community/tutorials/writing-resnet-from-scratch-in-pytorch\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1),\n",
    "                                   nn.BatchNorm2d(out_channels),\n",
    "                                   nn.ReLU())\n",
    "        self.conv2 = nn.Sequential(nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
    "                                   nn.BatchNorm2d(out_channels))\n",
    "        self.downsample = downsample\n",
    "        self.relu = nn.ReLU()\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, num_classes = 10):\n",
    "        # layers = [3, 4, 6, 3]\n",
    "        layers = [2, 2, 2, 2]\n",
    "        super(ResNet, self).__init__()\n",
    "        self.inplanes = 64\n",
    "        self.conv1 = nn.Sequential(\n",
    "                        nn.Conv2d(3, 64, kernel_size = 7, stride = 2, padding = 3),\n",
    "                        nn.BatchNorm2d(64),\n",
    "                        nn.ReLU())\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n",
    "        self.layer0 = self._make_layer(ResBlock, 64, layers[0], stride = 1)\n",
    "        self.layer1 = self._make_layer(ResBlock, 128, layers[1], stride = 2)\n",
    "        self.layer2 = self._make_layer(ResBlock, 256, layers[2], stride = 2)\n",
    "        self.layer3 = self._make_layer(ResBlock, 512, layers[3], stride = 2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def _make_layer(self, ResBlock, planes, blocks, stride=1):\n",
    "        print(f\"Making layer with {planes} planes\")\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes:\n",
    "\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm2d(planes),\n",
    "            )\n",
    "        layers = []\n",
    "        layers.append(ResBlock(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(ResBlock(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer0(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "82385f19-00d1-48ba-8381-cd6cc5267632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making layer with 64 planes\n",
      "Making layer with 128 planes\n",
      "Making layer with 256 planes\n",
      "Making layer with 512 planes\n",
      "Acc:  68\n"
     ]
    }
   ],
   "source": [
    "res_net = train(ResNet, trainloader, optim.SGD, device=gpu, lr=0.007, momentum=0.9)\n",
    "res_net_acc = test(nets5[-1], testloader, device=gpu)\n",
    "print(f\"Acc: {res_net_acc: .0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3a98e9-2fd1-4fa6-9162-86cde3c62547",
   "metadata": {},
   "source": [
    "# Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4291ae25",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 3.1600e-02,  4.5054e-02,  1.1591e-02,  1.0247e-01, -1.1023e-01],\n",
      "          [-1.5258e-02,  6.4661e-02,  1.1234e-02, -1.6596e-02, -3.8726e-03],\n",
      "          [ 5.4763e-02, -1.7057e-02, -7.3655e-02,  1.0306e-01,  1.6145e-02],\n",
      "          [ 1.4092e-02, -3.1699e-02, -3.2882e-02,  3.3918e-02, -5.5739e-02],\n",
      "          [-6.8762e-02, -1.3512e-02,  2.4894e-02, -5.8581e-03,  2.1964e-02]],\n",
      "\n",
      "         [[-7.0406e-02,  6.5489e-02,  3.6116e-02, -1.1181e-01,  1.4533e-02],\n",
      "          [ 7.7778e-02, -1.0411e-01, -6.4189e-02, -1.0278e-01,  3.1882e-03],\n",
      "          [ 5.9914e-02,  4.4581e-02,  5.8595e-02, -8.0919e-02, -5.1720e-02],\n",
      "          [-5.6214e-02,  3.8414e-02,  9.7419e-02, -7.2217e-02, -1.0158e-01],\n",
      "          [-5.2495e-02,  2.3259e-02, -5.7799e-02,  2.6712e-03, -5.7352e-02]],\n",
      "\n",
      "         [[ 8.9496e-02,  5.7826e-02,  4.6927e-03,  4.1311e-02,  1.4761e-02],\n",
      "          [-1.0366e-01, -5.2102e-02, -7.2886e-02, -6.4115e-02,  7.8429e-02],\n",
      "          [-3.0173e-02, -9.6887e-03, -2.4090e-02, -1.1329e-01, -2.0763e-02],\n",
      "          [-3.2893e-02,  3.2496e-02, -8.4201e-02, -6.9396e-02,  1.7823e-02],\n",
      "          [ 8.8698e-02,  1.0021e-01,  1.0733e-01,  1.0905e-01, -2.2554e-03]]],\n",
      "\n",
      "\n",
      "        [[[-4.3000e-02,  7.7443e-03,  9.0808e-02, -6.3785e-02,  3.6152e-02],\n",
      "          [ 1.6211e-02, -7.3534e-03, -4.3813e-02,  4.7960e-02,  2.3837e-02],\n",
      "          [ 3.0512e-02,  2.1379e-02,  4.0276e-02, -5.2360e-02,  2.8381e-02],\n",
      "          [ 4.9563e-03, -2.0460e-02,  2.7816e-02, -1.5281e-02,  9.2287e-02],\n",
      "          [-1.0459e-01,  3.9512e-03, -7.2130e-02,  1.0581e-01,  5.2311e-02]],\n",
      "\n",
      "         [[-8.8841e-02,  1.1387e-01,  9.5480e-02,  1.0901e-01,  4.0958e-02],\n",
      "          [-4.7199e-02, -6.0587e-02, -6.1033e-02,  1.5355e-02,  4.1607e-02],\n",
      "          [-7.5041e-02,  7.0249e-03, -4.4078e-05,  2.5615e-02, -1.1508e-01],\n",
      "          [ 2.5876e-02, -2.8739e-02, -3.2202e-02,  1.0882e-01, -9.2197e-02],\n",
      "          [-1.1701e-02,  9.7044e-02, -6.9325e-02, -8.2410e-02, -8.5605e-02]],\n",
      "\n",
      "         [[-8.7575e-02, -9.7320e-02, -1.2779e-02, -8.1392e-02,  9.0386e-02],\n",
      "          [-2.6115e-02,  2.8560e-02,  3.9214e-02,  9.3662e-02,  1.1273e-01],\n",
      "          [ 7.8206e-02,  9.3290e-02, -8.1980e-02,  6.1764e-02, -4.1888e-02],\n",
      "          [ 8.2343e-02, -1.0699e-01, -7.4985e-02,  5.8919e-02, -6.3484e-02],\n",
      "          [ 7.1920e-02,  1.0376e-01, -1.2611e-02, -1.1142e-01,  5.2954e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 3.8823e-02, -3.1434e-02,  3.5863e-02,  6.0206e-02, -9.4018e-02],\n",
      "          [ 1.7180e-02, -1.0329e-01,  5.0429e-02, -5.7379e-02,  3.1770e-02],\n",
      "          [ 5.5215e-02,  5.2173e-02, -3.1485e-02,  1.0691e-01, -2.2847e-02],\n",
      "          [-3.9723e-02, -9.0605e-02,  1.0479e-01,  9.8853e-02,  1.7592e-02],\n",
      "          [ 9.4111e-02,  6.0532e-02,  3.8837e-02, -5.9825e-02,  8.4844e-02]],\n",
      "\n",
      "         [[ 3.4896e-02,  1.1143e-01, -1.9872e-02, -4.4382e-02, -9.4104e-02],\n",
      "          [ 9.1544e-03, -4.5252e-02, -1.2499e-02,  5.3258e-03, -1.0503e-01],\n",
      "          [-6.5063e-02, -1.8359e-02, -6.9377e-02, -1.1965e-02,  6.3109e-02],\n",
      "          [-1.1374e-01, -1.3756e-02, -5.9183e-02,  3.2390e-02, -2.8849e-02],\n",
      "          [-4.2912e-02, -4.5039e-02, -6.7952e-02,  1.4431e-02, -2.4503e-02]],\n",
      "\n",
      "         [[-6.7049e-02, -4.5025e-02,  4.2575e-02, -1.1181e-01,  3.6309e-02],\n",
      "          [-7.3452e-02, -3.6744e-02, -6.0247e-02, -1.0897e-01,  2.4958e-02],\n",
      "          [ 7.9293e-02,  8.2748e-02, -1.0842e-02, -1.0433e-01,  3.3192e-02],\n",
      "          [-7.6717e-02, -5.6634e-02, -4.0723e-02,  2.2612e-02, -9.1587e-02],\n",
      "          [-8.9455e-02, -5.5934e-03,  7.8386e-02,  6.5562e-02, -2.2455e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 5.7833e-02,  1.0931e-01,  6.0471e-02, -7.0670e-02, -9.0315e-02],\n",
      "          [ 1.7006e-02, -4.8221e-02,  8.1072e-02,  4.2714e-02,  7.5934e-02],\n",
      "          [ 5.4862e-02, -5.0954e-02,  2.0597e-02, -8.0611e-02, -1.0798e-01],\n",
      "          [ 3.6888e-03,  1.0223e-01,  3.7171e-02, -6.3352e-02,  7.3750e-02],\n",
      "          [ 9.7149e-03,  6.7925e-03,  1.9723e-03, -7.2689e-02, -2.0811e-03]],\n",
      "\n",
      "         [[-5.6388e-02,  9.6873e-02, -4.1864e-02,  4.6061e-02,  2.3868e-02],\n",
      "          [ 3.5061e-02,  2.2536e-02,  7.1949e-02, -2.0612e-02,  4.7603e-02],\n",
      "          [ 2.1321e-02,  1.7700e-02, -2.6455e-02,  8.8123e-02,  6.6518e-02],\n",
      "          [ 1.0313e-01,  6.8346e-02,  2.3014e-02, -9.9385e-02,  8.4435e-02],\n",
      "          [-2.9746e-02, -4.7924e-02,  2.8297e-02,  5.1548e-02, -4.7673e-02]],\n",
      "\n",
      "         [[-5.2577e-02,  9.9947e-02, -5.5442e-02, -5.8983e-02,  1.0084e-01],\n",
      "          [ 4.9589e-02, -3.1590e-02,  1.5534e-02, -9.1104e-02,  7.8888e-03],\n",
      "          [-5.9014e-02,  1.1182e-01,  9.6914e-02, -6.1002e-02,  2.0853e-03],\n",
      "          [ 7.5420e-02, -5.2942e-02,  8.8628e-02, -6.9707e-02,  1.0622e-01],\n",
      "          [-4.8773e-02,  6.5086e-02, -7.8797e-02,  9.9888e-02,  1.0388e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.3551e-02,  6.9375e-03,  1.4711e-02, -4.7382e-02, -6.2270e-02],\n",
      "          [ 1.0551e-01, -8.0656e-02, -2.1415e-02,  4.3713e-02, -7.0553e-03],\n",
      "          [ 1.0348e-01, -9.0598e-02,  1.0530e-01,  4.1047e-02,  4.5327e-02],\n",
      "          [ 2.9583e-02, -2.7827e-02, -3.1410e-02,  7.3256e-02,  1.5220e-03],\n",
      "          [-2.7689e-02, -1.0174e-01,  5.9081e-02, -9.3488e-02,  4.0253e-02]],\n",
      "\n",
      "         [[-1.4767e-02,  4.5695e-02, -3.7948e-02,  1.4755e-02,  9.3983e-02],\n",
      "          [ 9.6823e-02,  5.8917e-02,  4.5903e-02,  1.1446e-01,  9.5257e-02],\n",
      "          [ 1.8878e-02, -2.8872e-03, -3.1770e-02,  5.8184e-02,  4.3917e-02],\n",
      "          [ 2.3316e-02, -5.2011e-02, -6.0374e-03,  3.1644e-02, -3.1573e-02],\n",
      "          [-6.6264e-03,  7.3433e-02,  6.8084e-02, -1.0789e-01,  7.1339e-02]],\n",
      "\n",
      "         [[ 2.6450e-02,  4.4744e-02,  9.5061e-02, -1.1338e-01, -9.0156e-02],\n",
      "          [ 5.7329e-02,  1.7559e-02,  1.6714e-02, -1.0671e-01, -1.1445e-01],\n",
      "          [-4.0377e-02, -2.5218e-02, -8.7985e-02,  2.4778e-02, -1.1325e-01],\n",
      "          [ 4.3098e-02, -1.5729e-02,  7.9126e-03,  3.4288e-02, -6.9145e-02],\n",
      "          [ 1.1036e-02,  8.3662e-02, -6.7286e-02, -8.0809e-02,  3.9998e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 8.4023e-02,  6.3200e-02,  8.2949e-02,  1.3187e-02, -1.1439e-01],\n",
      "          [-7.3339e-02,  8.2576e-02, -1.0183e-01, -1.0930e-01, -9.7964e-02],\n",
      "          [ 8.8003e-03, -4.6899e-02,  5.4738e-02,  3.5904e-03,  2.6301e-02],\n",
      "          [ 3.8637e-02,  1.1622e-02,  9.4480e-02, -6.6231e-02,  1.6317e-02],\n",
      "          [-4.0537e-02,  9.7984e-02, -4.6715e-02, -4.7289e-02, -8.4400e-02]],\n",
      "\n",
      "         [[-2.5976e-02,  8.3178e-02,  1.0756e-01, -6.6499e-02,  6.4211e-02],\n",
      "          [-7.7275e-02,  8.2869e-02, -9.8814e-02,  8.0967e-02, -4.0761e-02],\n",
      "          [ 9.6119e-02,  7.6227e-02,  3.1194e-02,  9.7599e-02, -1.0120e-01],\n",
      "          [ 4.5290e-02,  4.9287e-02,  6.1284e-02, -7.4482e-02,  2.5224e-02],\n",
      "          [-2.6358e-02, -5.0095e-02,  1.0513e-01,  1.0163e-01,  1.0674e-01]],\n",
      "\n",
      "         [[-4.4649e-02, -3.0717e-02,  5.1971e-02,  6.2856e-02,  1.2484e-02],\n",
      "          [-4.8313e-02, -1.0717e-02, -3.4522e-02, -7.6785e-02, -8.6454e-02],\n",
      "          [-3.3258e-02, -1.0473e-01,  8.4408e-02, -8.0622e-02,  6.7747e-02],\n",
      "          [-4.4948e-02,  4.4025e-02, -2.9168e-02,  5.1231e-04, -6.5650e-02],\n",
      "          [ 6.2356e-03,  1.1432e-01, -1.1457e-01, -5.6176e-02, -4.5690e-02]]]])\n"
     ]
    }
   ],
   "source": [
    "from itertools import permutations, product\n",
    "\n",
    "conv = [{\"kernel_size\": 5, \"out_channels\": 32, \"padding\": 3},\n",
    "        {\"kernel_size\": 3, \"out_channels\": 64, \"padding\": 2}]\n",
    "\n",
    "sizes = (2400, 400, 400)\n",
    "\n",
    "net = make_Net(conv, sizes, pool=nn.MaxPool2d(2, 2), drop_softmax=True)()\n",
    "\n",
    "print(net.convs[0].weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d452b619-ca5b-46e2-a12a-0e02df947608",
   "metadata": {},
   "outputs": [],
   "source": [
    "Net2 = make_Net([(16, 5), (16, 5)], [1200, 84*5], pool=nn.AvgPool2d(2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc928a8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "net2, losses = train(Net2, trainloader, optim.SGD, device=gpu, lr=0.007, momentum=0.9, get_losses=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99d57db-5a67-4779-a693-f70a3632e0f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adbf2d7-aafd-4442-a651-7e4cd11646e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b80865-b670-4657-84b1-27c7cfd5a8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ylim(0, max(losses)*1.02)\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baea134f-00e5-49c8-9757-8c7a78044894",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb70472-a53b-444e-b214-e84916f7893e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
